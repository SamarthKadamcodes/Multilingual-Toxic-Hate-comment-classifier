# Toxic Comment Detection (Logistic Regression)

A simple machine learning model built with **Logistic Regression** to classify comments as **toxic** or **non-toxic**.  
This is the initial version of a larger project that later evolved into a multilingual transformer-based toxicity detection system.

CSV File: https://www.kaggle.com/competitions/jigsaw-multilingual-toxic-comment-classification

---

## üìå Concept
The goal is to detect harmful or toxic language in text comments using traditional **Natural Language Processing (NLP)** techniques combined with **Logistic Regression**.  
This baseline model demonstrates how classical machine learning methods can be applied to text classification tasks.

---

## ‚öôÔ∏è Tech Stack
- **Python**
- **Scikit-learn**
- **Pandas & NumPy**
- **NLTK / SpaCy** (for preprocessing)
- **Flask** (for simple web deployment)

---

## üìÇ Project Structure
---

## üöÄ How to Run

1. Clone this repository  
   ```bash
   git clone https://github.com/your-username/toxic-comment-logistic-regression.git
   cd toxic-comment-logistic-regression
